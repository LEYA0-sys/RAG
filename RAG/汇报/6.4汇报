本周API调用大语言模型，速度提高，决定不采取本地部署的llm
1.混合检索部分跑整个QA对，时长控制在1h内，alpha=0.5结果如下：
k=50:
        "avg_recall": 0.9279279279279279
        "avg_mrr": 0.4487184400271942

2.多查询检索+混合检索+去重
PROMPT_TEMPLATE = """您是查询扩展方面的专家，能够生成问题的释义。
我无法直接使用用户的问题从知识库中检索相关信息。
您需要通过多种方式扩展或释义用户的问题，例如使用同义词/短语、完整地写出缩写、添加一些额外的描述或解释、改变表达方式、将原始问题翻译成中文等。
并返回 5 个版本的问题，其中一个来自翻译。
只需列出问题。不需要其他单词。
原始问题：{query}"""

跑整个QA对,使用模型"doubao-1.5-thinking-pro-m-250428"，耗时1h
k=50:
    "avg_recall": 0.972972972972973
    "avg_mrr": 0.4361244584928367
在此基础上提升mrr，基于LLM的rerank进行重排序
由于额度有限，所以没有继续尝试

3.生成部分添加四个指标：
        "bleu": 关注精确匹配和词序，可能忽略同义词
        "rouge-1": 关注词汇覆盖（单个词的匹配程度）
        "rouge-2": 关注词语准确性（两个词的匹配程度）
        "rouge-l": 关注整体语义连贯性（最长公共子序列的匹配长度）

速度较快
没有压缩,直接对混合检索的部分进行问答：
对于outputs\outputs_4.0\混合检索\hybrid_results_k=50.json文件：
MODEL_NAME = "doubao-1.5-thinking-vision-pro-250428"

  "bleu_average": 0.08112694914858423,
  "rouge_average": 0.0025955148918100353,
  "average_metrics": {
    "bleu": 0.08112694914858423,
    "rouge-1": 0.004464285618024556,
    "rouge-2": 0.0,
    "rouge-l": 0.003322259057405549
   }

待办：
1.检索部分——重排序
2.生成部分——优化，对比上下文压缩的效果
3.都转化为简体字
