# FISHNET

## 关键词

### 金融领域

论文使用的 98034 份监管文件全部来自**美国金融市场监管体系**

| 文件类型   | 来源机构          | 金融属性     | 覆盖内容示例                                        | Agent  |
| ---------- | ----------------- | ------------ | --------------------------------------------------- | :----- |
| **13F**    | SEC（美国证监会） | 证券持仓     | 投资经理季度股票/衍生品持仓                         | 13-F   |
| **N-PORT** | SEC               | 投资基金     | 公募基金月度/季度投资组合明细                       | N-PORT |
| **N-MFP**  | SEC               | 货币市场基金 | 货基月度持仓及风险敞口                              | N-MFP  |
| **ADV**    | SEC/IAPD          | 投资顾问     | 投资顾问公司基本信息、客户类型、资产管理规模（AUM） | ADV    |
| **N-CEN**  | SEC               | 基金普查     | 公募基金年度运营数据（托管人、承销人等）            | N-CEN  |
| **N-CSR**  | SEC               | 基金年报     | 经审计的基金财务报表、投资组合                      | N-PORT |

### Agent

1. 一个会“读文件-检索-计算”的 LLM 专用小助手

2. 每个 Agent 都有自己的 **向量索引 + Prompt 模板 + 字段解释器**， 内部只有 **1 个 LLM**（gpt-3.5-turbo 或 gpt-4），返回数据结构也因文件类型而异（XML、CSV、嵌套 JSON）

3. 一类Agent负责一类监管文件，基于不同文件类型开发专用Agent;一共有5类Agent

   > [!NOTE]
   >
   > 论文主要包含了6种文件类型，由于N-CSR和N-PORT同属“基金类”结构XML，逻辑处理高度重叠，所以合并为1个N-PORT Agent

4. 5类Agent

   | Agent            | 专属文件       | 核心职责             | 关键差异示例                                |
   | ---------------- | -------------- | -------------------- | ------------------------------------------- |
   | **13F Agent**    | Form 13F       | 解析投资经理季度持仓 | 字段：`CUSIP`、`issuer_name`、`value`       |
   | **N-PORT Agent** | N-PORT + N-CSR | 解析公募基金组合     | 字段：`portfolio_assets`、`swap_notionals`  |
   | **N-MFP Agent**  | Form N-MFP     | 解析货币市场基金持仓 | 字段：`net_assets`、`WAM`、`WAL`            |
   | **ADV Agent**    | Form ADV       | 解析投资顾问档案     | 字段：`AUM`、`clients`、`disciplinary_info` |
   | **N-CEN Agent**  | Form N-CEN     | 解析基金年度普查     | 字段：`fund_type`、`financial_support`      |

### Swam

一种 **AI 协作机制**

- **一群同质的 LLM 实例**（论文用 5 个 gpt-3.5-turbo）  
- **没有固定领袖**  
- **2-3 轮投票 / 讨论** 后，把 **多数或加权结果** 作为最终答案  

就像蜂群找花源：每只“蜂”独立给出意见 → 互相交流 → 收敛到全局最优。  

用在 FISHNET 中，蜂群负责  在任务执行过程中的决策和结果验证

**步骤**

| 步骤       | 代码级动作                                             |
| ---------- | ------------------------------------------------------ |
| ① 并行生成 | 把子查询 `q` 同时发给 5 个 `gpt-3.5-turbo`             |
| ② 投票规则 | 取 **多数答案**；若票数平局 → 用 **log-prob 加权平均** |
| ③ 输出共识 | 返回 `consensus_answer` + `confidence_score`           |

## 研究背景

一句话总结  
> 传统金融监管数据格式杂、体量大，现有方法不是“人肉搜索”就是“重训大模型”，成本高、易幻觉；因此需要一种**不微调、可扩展、能自动跨文件计算**的新范式

---

### 具体问题
| 层级       | 现状                                                         | 问题                              |
| ---------- | ------------------------------------------------------------ | --------------------------------- |
| **数据层** | 98 034 份监管文件（13F、N-PORT、ADV…）<br>格式、本体、频率各不同 | 传统知识图谱/数据库难覆盖全部字段 |
| **方法层** | • 人工在 PDF/Excel 里翻查 → 耗时<br>• 对 LLM 精调 → 封闭源模型贵、不可控 | 复杂查询（跨表计算）成功率低      |
| **需求层** | 监管、资管、券商需实时回答：<br>“某银行 Q2 单股掉期钱包份额” | 要求**低成本、可解释、可溯源**    |

→ 催生 **Agent-Based 蜂群框架**，把“文件专家”+“蜂群投票”+“指挥协调”拼成流水线，实现**零微调、高成功率**的金融洞察。

## 实验流程

> [!WARNING]
>
> 代码未开源

---

### **一、实验设计：验证 FISHNET 的性能**

#### **1.1 数据集构建**

> [!CAUTION]
>
> 这一步和项目实践的数据集构建步骤相似，对原始数据进行结构化、向量化，并且存储在FAISS索引中

- **数据来源**：  
  - 从 美国金融监管体系中两个**核心的公开数据库**（EDGAR 和 IAPD ）爬取 **98,034 份监管文件**，涵盖 6 种类型（13F、N-PORT、N-MFP、ADV、N-CEN、N-CSR）。  
  - 每种文件类型在格式、字段、频率上差异极大，例如：
    - **13F**：投资经理季度持仓报告（XML 格式，字段包括 CUSIP、issuer_name、value 等）。  
    - **N-PORT**：公募基金月度投资组合报告（XML 格式，字段包括 portfolio_assets、swap_notionals 等）。  
    - **ADV**：投资顾问年度报告（PDF 格式，字段包括 AUM、clients、disciplinary_info 等）。

- **数据预处理**：  
  
  - 将所有文件解析为结构化格式。  
  
  - 使用 Ada-2 嵌入模型将每行数据向量化，生成 5,052,421 个 1536 维向量，存储在 FAISS 索引中，用于快速检索。

#### **1.2 问题生成**
- **问题模板**：  
  - 设计 7 种简单问题模板和 4 种复杂问题模板，覆盖不同文件类型和查询场景。  
  - 例如：
    - **简单问题**：获取某投资经理的总持仓金额（13F 文件）。  
    - **复杂问题**：计算某银行在最新季度的单股掉期钱包份额（涉及 N-PORT 和 13F 文件）。

- **问题变体**：  
  - 使用 GPT-3.5-turbo 对每个模板问题生成 2 个变体，增加问题的多样性和复杂性。  
  - 每个问题都附带 **标准答案** 和 **所需数据行清单**，用于自动评估。

#### **1.3 评估指标**
- **Retrieval**：使用 R-Precision 评估检索性能，衡量检索结果的相关性。  

  **判断标准**：

  - 精确率定义为检索到的相关文档数与检索到的文档总数的比例。在 R-Precision 中，R 表示针对每个查询检索到的相关文档数量。

  **评估方法**：

  - 对于每个查询，系统会返回一组文档。评估者会检查这些文档中有多少是真正相关的。
  - 通常，会针对每个查询计算 R-Precision，并取平均值作为最终的检索性能指标

- **Routing**：评估 LLM查询被正确分配到相应处理 Agent 和子表的能力 

  **判断标准**：

  - 正确识别相关的 Agent。
  - 正确选择适当的子表以进行进一步处理。

  **评估方法**：

  - 构建一个混淆矩阵，记录每个查询被路由到不同 Agent 的准确性。
  - 计算条件准确率（准确性依赖于正确识别 Agent 和子表）。

- **Agentic**：评估整个系统架构生成准确解决方案的成功率。

  **判断标准**：

  - 成功创建准确解决方案的查询占总比例。

  **评估方法**：

  - 对于每个查询，跟踪从子查询生成到最终答案生成的全过程。
  - 确定每个查询是否成功生成了正确的答案。
  - 考虑简单问题和复杂问题（如需要跨表计算的问题）的成功率。



---

### **二、Agent、Swarm、Harmonizer 的协同工作**

#### **2.1 Sub-querying Agent**
- **输入**：原始查询 `Q`（如“Calculate Bank A's wallet share for single-stock swaps in 2024Q2”）。  
- **输出**：多个子查询 `q`（如 q1=获取总单股掉期金额，q2=获取 Bank A 的单股掉期金额，q3=计算比例）。  
- **过程**：  
  - 使用 HalluciBot 检测查询的幻觉概率，确保查询质量。  
  - 通过 In-Context Learning (ICL) 生成优化后的子查询。
  
  > [!NOTE]
  >
  > HalluciBot 可以帮助检测查询是否存在幻觉（hallucination）的可能性。幻觉是指**模型生成与输入不相关或不准确的输出**。通过 HalluciBot 的二元分类（幻觉或非幻觉），可以不断迭代查询，以确保查询的质量。
  >
  > In-Context Learning (ICL) 允许大型语言模型在推理过程中通过在提示中包含一些示例（演示）来进行少样本学习。有点类似提示词
  >
  > ```
  > 给定以下示例，请根据提供的查询生成相应的子查询：
  > 示例：
  > 1. 计算银行A在2023年第一季度的股权掉期交易份额。
  > 2. 确定银行B在2023年第四季度的股权掉期交易总量。
  > 
  > 查询：计算银行X在2024年第二季度的股权掉期交易份额。
  > ```
  >
  > ![image-20250807211210648](./%E7%AC%AC%E4%BA%8C%E5%91%A8-%E9%98%85%E8%AF%BB%E6%96%87%E7%8C%AE.assets/image-20250807211210648-1754572331980-1.png)
  

#### **2.2 Task Planning Agent**
- **输入**：子查询 `q`。  
- **输出**：初步任务计划，指定每个子查询由哪个 Agent 处理。  
- **过程**：  
  - 使用 ICL 和少量示例生成初步计划。  
  - 例如，q1 分配给 N-PORT Agent，q2 分配给 13F Agent。

#### **2.3 Expert Agents**
- **输入**：子查询 `q` 和相关文件类型。  
- **输出**：结构化数据。  
- **过程**：  
  - 每个 Agent 专注于一种文件类型，在指定文件类型中解析并返回所需数据。  

#### **2.4 Swarm Voting**
- **输入**：Expert Agents 返回的结构化数据。  
- **输出**：共识结果和置信度分数。  
- **过程**：  
  - 5 个相同的 LLM 实例并行处理每个子查询，生成 5 个答案。  
  - 通过多数投票或置信度加权平均选择最终答案。
    1. **LLM 如何处理子查询**  
       - 这些结构化数据会被转换成适合 LLM 处理的格式（例如，文本描述或特定的查询语句）。  
       - LLM 实例会根据这些格式化后的数据和查询描述生成答案。
    2. **投票的内容**  
       - **不是对原始的 Agent 输出进行投票**，而是对 LLM 实例生成的**答案的准确性**进行评估。  
       - 具体来说，5 个 LLM 实例（克隆出来的相同模型）会分别独立地评估每个答案的准确性，并给出一个置信度分数（或直接投票决定哪个是正确的）。
    3. **过程详解**  
       - 每个 LLM 实例接收相同的结构化数据和相同的子查询。  
       - 它们并行生成各自的答案，这些答案会基于它们对数据的理解和查询的解释。  
       - 然后，系统会比较这些答案，通过**多数投票**（如果答案一致，选择该答案；如果不一致，选择出现次数最多的答案）或**置信度加权平均**（对每个答案的准确性评分进行平均）来确定最终的共识结果。

#### **2.5 Harmonizer**
- **输入**：Swarm 的共识结果和 Expert Agents 的原始数据。  
- **输出**：最终答案和溯源信息。  
- **过程**：  
  - 汇总所有 Agent 的结果，进行交叉验证和数值运算。  
  - 生成最终答案+溯源数据：
  
    1. **最终答案来自于蜂群（Swarm）**：
       - 蜂群中的每个 LLM 实例（智能体）独立地处理相同的子查询和结构化数据。
       - 这些智能体并行工作，生成各自的答案。
       - 系统通过多数投票或置信度加权平均等方法，从这些答案中选出最终的共识结果作为最终答案。
  
    2. **溯源数据来自于各智能体（Expert Agents）**：
       - 每个 Expert Agent 专门处理一种类型的文件，从原始文档中提取和解析出所需的数据。
       - 这些数据包括了回答查询所必需的所有相关信息，并且以结构化的形式输出。
       - 当 Harmonizer 生成最终答案时，它不仅使用 Swarm 的共识结果，还会汇总各 Expert Agent 提供的原始数据和解析结果。
       - 最终答案将附带详细的溯源信息，这些信息展示了所有参与生成答案的文件和数据点，确保了答案的透明度和可验证性。
  

---

## **实验结论**

#### **性能对比**
- **FISHNET**：整体成功率为 **61.8%**，显著优于传统 RAG（5.0%）。  
- **复杂问题**：FISHNET 在复杂问题（需跨表计算）上的成功率为 **28.3%**，而传统方法几乎无法解决此类问题。  
- **简单问题**：FISHNET 在简单问题上的成功率为 **81.0%**，表现出色。

#### **关键发现**
- **分层索引优于全局索引**：按 Agent → Table → Row 的三级嵌入显著优于“一锅端”RAG，特别是在 NCSR 文件上，R-Precision 提升 38%。  
- **生成式路由 + 蜂群投票**：gpt-3.5-turbo 做 Agent 路由可达 **82%** 准确率，再经蜂群微调稳定性更高。  
- **模块化即插即用**：新增文件类型只需再训练一个 Expert Agent，无需重训大模型。

#### **启示**
- **可直接迁移**：FISHNET 架构可直接迁移到其他强监管行业（如保险、医疗），只需替换 Expert Agent 即可。  
- **下一步**：  
  - 非英语金融文件的适配。  
  - 微调轻量级模型做 Expert Agent，进一步降本增效。

---

## **总结**
FISHNET 通过 **“拆解问题 → 分布式检索 → 蜂群投票 → 中央协调”** 的流程，成功解决了传统方法在复杂金融查询上的痛点，显著提升了查询成功率和鲁棒性。

## 思考

### FISHNET 与 RAG 的本质区别

1. **多智能体系统（Multi-Agent System）**：
   - **RAG**：主要依赖单一的大型语言模型（LLM）进行信息检索和生成。
   - **FISHNET**：采用多个专门化的智能体（Agent），每个智能体负责处理特定类型的任务或数据，通过协作完成任务。

2. **中央协调器（Central Coordinator）**：
   - **RAG**：通常没有中央协调器，检索和生成过程较为直接。
   - **FISHNET**：包含一个 Harmonizer，负责协调各智能体的工作，汇总结果，并进行最终的决策。

3. **群体智能（Swarm Intelligence）**：
   - **RAG**：不涉及群体智能，单一模型独立工作。
   - **FISHNET**：利用群体智能（Swarm Intelligence）来提高决策的准确性和鲁棒性，通过多个智能体的并行工作和投票机制来优化结果。

4. **任务规划（Task Planning）**：
   - **RAG**：任务规划通常不明确，模型直接从问题到答案。
   - **FISHNET**：有明确的任务规划阶段，通过规划智能体（Task Planning Agent）来制定和优化任务执行计划。

### 应用到保险领域的可行性

- **数据结构化**：保险数据可能包含保单、索赔、医疗记录等多种格式，FISHNET 的多智能体架构可以针对不同数据类型开发专用的智能体。
- **复杂查询处理**：保险领域可能需要处理复杂的跨表查询和计算，FISHNET 的任务规划和群体智能特性有助于处理这类问题。
- **可解释性和可追踪性**：保险决策通常需要高度的可解释性，FISHNET 的模块化设计有助于追踪决策过程和结果。

### 更换为 FISHNET 方法

#### 一、系统设计

1. **定义任务和数据类型**：
   - 确定保险领域中需要处理的主要任务类型（如索赔处理、保单分析、客户服务等）。
   - 确定涉及的数据类型（如保单、医疗记录、索赔表格等）。

2. **设计智能体（Agent）架构**：
   - 为每种数据类型和任务设计一个或多个专用的 Expert Agent。
   - 确定每个 Agent 的职责范围和所需的特定能力。

3. **设计 Harmonizer 架构**：
   - 设计一个中央协调器（Harmonizer），负责汇总各 Agent 的结果，进行最终决策。

4. **设计 Swarm Intelligence 流程**：
   - 确定如何利用多个 LLM 实例进行群体决策和结果优化。

#### 二、数据处理

1. **数据收集和预处理**：
   - 收集所需的保险数据，并进行必要的清洗和格式化处理。

2. **数据结构化和索引**：
   - 将数据转换为结构化格式。
   - 使用适当的嵌入模型（如 Ada-2）将数据向量化，并建立索引以支持快速检索。

3. **创建训练和测试数据集**：
   - 根据任务类型创建训练和测试数据集，包括输入数据和预期输出。

#### 三、智能体开发

1. **开发 Expert Agents**：
   - 为每种数据类型和任务开发专用的 Agent，每个 Agent 能够理解其专属数据的语义和结构。
   - 例如，开发一个专门处理保单数据的 Agent，另一个处理索赔表格。

2. **实现 Harmonizer**：
   - 开发一个中央协调器，它能够整合来自不同 Agent 的信息，并执行必要的计算和决策。

3. **实现 Swarm Intelligence**：
   - 设计一个机制，让多个 LLM 实例能够对任务进行并行处理，并通过投票或加权平均等方式达成共识。

#### 四、系统集成

1. **集成 Sub-querying Agent**：
   - 实现一个能够将复杂查询分解为多个子查询的 Agent，以便于并行处理。

2. **集成 Task Planning Agent**：
   - 实现一个能够制定和优化任务执行计划的 Agent，它将利用少量示例和上下文学习来初始化计划。

3. **集成 Swarm 和 Harmonizer**：
   - 将 Swarm Intelligence 和 Harmonizer 集成到系统中，确保系统能够有效地整合来自多个 Agent 的输出。

#### 五、系统测试和评估

1. **单元测试**：
   - 对每个 Agent 进行单独测试，确保它们能够正确处理其指定的数据和任务。

2. **集成测试**：
   - 测试整个系统的工作流程，包括查询分解、任务规划、并行处理、结果汇总和最终输出。

3. **性能评估**：
   - 使用预定义的评估指标（如准确率、召回率、F1分数）来评估系统的性能。

4. **迭代优化**：
   - 根据测试结果对系统进行调整和优化，提高准确性和效率。

#### 六、部署和监控

1. **部署系统**：
   - 将系统部署到生产环境中，确保所有组件正常运行。

2. **监控和维护**：
   - 监控系统的性能和健康状态，定期进行维护和更新。

3. **用户反馈**：
   - 收集用户反馈，根据实际使用情况进一步改进系统。

