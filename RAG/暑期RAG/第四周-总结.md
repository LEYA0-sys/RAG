# 论文1——FinTextQA

文献来源：https://arxiv.org/pdf/2405.09980  - 金融领域数据集

## 总结内容

文章的创新点在于提出第一个金融领域的长文本问答基准数据集**，并且设计实验：拿这个数据集**测试12种RAG组合**（嵌入+检索+重排序+生成）最后得到实验结论——最佳配置为“Ada2+AMR+Bge-Reranker+Baichuan2-7B”

## 文章架构

### 📌总结

这篇论文的结构是：**“问题 → 数据 → 系统 → 实验 → 结论”**，是一篇**数据集构建 + 系统实验评估**类论文。

每一步都围绕“如何构建一个高质量的金融LFQA系统”展开。

---

### 📌 1. 标题与摘要（Title & Abstract）
- **标题结构**：任务 + 数据集名称 + 方法或贡献  
  例：`FinTextQA: A Dataset for Long-form Financial Question Answering`
- **摘要结构**（4句话）：
  1. 研究背景（金融问答难、现有数据不足）
  2. 提出什么（新数据集FinTextQA）
  3. 做了什么（构建RAG系统+多维度评估）
  4. 主要结论（最佳配置、模型表现）

---

### 📌 2. Introduction（引言）
- **四段式结构**：
  1. 背景：金融问答的重要性
  2. 问题：现有数据集不适用于长文本、复杂推理
  3. 研究空白：没有金融领域的LFQA数据集
  4. 本文贡献：提出FinTextQA + 构建RAG系统 + 多维度评估

---

### 📌 3. Related Work（相关工作）
- **分类写**，不要堆叠：
  - 2.1 LFQA数据集（如ELI5、WikiHowQA）
  - 2.2 RAG系统发展（Naive → Advanced → Modular）
- **每段结尾加一句**：这些方法/数据集的不足 → 引出我们的工作

---

### 📌 4. Dataset Construction（数据集构建）
- **结构化写**：
  - 数据来源（教材、政府网站）
  - 数据筛选流程（证据识别 + 相关性评分）
  - 数据统计（问题类型、长度、分布）
  - 与其他数据集对比（表2）
- **图表辅助**：用表格+柱状图展示数据分布、问题类型

---

### 📌 5. Experiments（实验部分）
- **系统架构图**（如Figure 2）：
  - Embedder → Retriever → Reranker → Generator
- **模块化实验设计**：
  - 每个模块用不同模型组合（如Ada2 vs Ember-v1）
  - 用GPT-4评分 + ROUGE/BLEU + 人工排序
- **结果分析**：
  - 哪个组合最好（如AMR + Ada2 + Bge-Reranker + Baichuan2）
  - 模型在噪声文档下的鲁棒性（Figure 4）

---

### 📌 6. Conclusion + Limitations + Ethics
- **结论**：总结数据集贡献、系统表现、未来方向
- **局限性**：数据量小、版权问题、模型偏差
- **伦理声明**：数据来源合法、标注者待遇、模型防滥用

---

## 模板句式参考

| 功能         | 示例句式                                                     |
| ------------ | ------------------------------------------------------------ |
| 引出研究空白 | *However, existing datasets primarily focus on... and lack...* |
| 提出贡献     | *To address this gap, we introduce ..., a novel dataset for...* |
| 数据来源     | *The dataset is curated from authoritative sources including...* |
| 质量控制     | *We implement a two-step verification process to ensure...*  |
| 实验结论     | *Experimental results show that the best configuration achieves...* |
| 局限性       | *Despite its quality, the dataset is limited in size due to...* |

## 可借鉴的地方

- 金融领域长文本问答数据集——>保险领域长文本问答数据集

- 生成部分的分数指标由ROUGE/BLEU/GPT-4分数，再加上论文3里面提到过的BERTScore，实验流程的生成部分可以引入四个分数

![image-20250816214324656](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250816214324656-1755351805696-1.png)

# 论文2——FISHNET

## 总结内容

一篇**多智能体系统 + 金融文档分析**方向的**系统类论文**，它展示了如何**用LLM Agents解决复杂的金融文档问答任务**。

## 文章架构

### 📌总结

这篇论文的结构是：**“问题 → 系统 → 数据 → 实验 → 结论”**，每一步都围绕“如何用多智能体系统解决复杂金融文档问答”展开

---

### 📌 1. 标题与摘要

- **标题结构**：系统名 + 缩写 + 关键词（任务+方法）  
  例：`FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning`

- **摘要结构**（4句话）：
  1. 背景：现有方法成本高/幻觉多
  2. 提出系统：FISHNET，模块化智能体架构
  3. 实验：98k监管文件，61.8%成功率，优于RAG
  4. 贡献：模块化、可扩展、无需微调

---

### 📌 2. Introduction（引言）

- **四段式结构**：
  1. 背景：金融文档复杂、监管文件多、问答难
  2. 问题：知识图谱构建慢、微调LLM贵、幻觉多
  3. 研究空白：缺乏多智能体系统处理金融文档
  4. 本文贡献：提出FISHNET，模块化设计，实验验证

---

### 📌 3. Methodology（系统设计）

- **模块清晰、职责分明**，每个Agent一段：
  1. **Sub-querying Agent**：拆解问题，降低幻觉
  2. **Task Planning Agent**：规划任务，协调Agent
  3. **Harmonizer Agent**：聚合结果，执行计划
  4. **Expert Agents**：每类文档一个Agent（如13F、N-PORT）
  5. **Swarming机制**：多智能体协同决策

- **图示**：系统图（Figure 2）+ 流程图（Figure 1）

---

### 📌 4. Datasets（数据来源）

- **数据来源**：EDGAR、IAPD等官方数据库
- **文件类型**：13F、N-PORT、N-MFP、N-CEN、N-CSR、ADV
- **数据处理**：
  - 下载、清洗、结构化
  - 每类文件的处理细节（XML、PDF、表格）
  - 修正文件（amendments）处理逻辑

- **表格展示**：每类文件的数量、格式、频率、是否结构化（Table 1）

---

### 📌 5. Metrics（评估指标）

- **三类指标**：
  1. **Retrieval**：R-Precision（检索精度）
  2. **Routing**：Agent识别准确率 + Table识别准确率
  3. **Agentic Success Rate**：整体任务成功率

- **公式清晰**：
  - R-Precision = |Relevant ∩ Retrieved| / R
  - Routing Accuracy = P(A) × P(S|A)

---

### 📌 6. Experiments（实验设计）

- **三类实验**：
  1. **嵌入检索对比**：Global vs Agent vs Table-level
  2. **路由方法对比**：Embedding vs Generative vs Swarming
  3. **系统成功率**：按难度/文件类型分

- **结果分析**：
  - 嵌入层级越细，R-Precision越高
  - Swarming优于单模型
  - 简单问题成功率高（81%），复杂问题低（28%）

---

### 📌 7. Conclusion（结论）

- **总结贡献**：
  - 提出FISHNET系统，模块化、可扩展
  - 无需微调，适用于复杂金融任务
  - 实验验证有效性

- **未来方向**：
  - 支持非英语文档
  - 拓展到保险、ESG报告等领域

---

## 模板句式参考

| 功能         | 示例句式                                                     |
| ------------ | ------------------------------------------------------------ |
| 引出研究空白 | *However, existing methods either require costly fine-tuning or struggle with hallucinations when handling complex financial documents.* |
| 提出系统     | *To address this, we propose FISHNET, a modular multi-agent system that decomposes queries, plans tasks, and harmonizes expert outputs.* |
| 模块描述     | *The Harmonizer Agent synthesizes outputs from expert agents and executes arithmetic operations as per the optimized plan.* |
| 实验结论     | *Experimental results show that FISHNET achieves a 61.8% success rate, outperforming RAG baselines by 56.8%.* |
| 未来方向     | *Future work will explore adapting FISHNET to non-English regulatory filings, such as EU insurance directives or Asian ESG reports.* |

## 可借鉴的地方

- 论文主要讲述了多个LLM智能体相互协作，和之前的RAG不同。RAG没有对不同类型的文件进行分类再检索，论文的智能体是针对不同的文件生成对应的专家智能体去检索，检索结果提交给5个LLM组成的蜂群去生成答案。

# 论文3——RAG-VA

## 总结内容

是一篇**工业界经验报告（experience report）**，系统总结了**如何从0到1构建并落地一个RAG虚拟助手（RAGVA）**，并提炼出**8大工程挑战+22个未来研究方向**。

## 文章架构

这篇论文的结构是：**“问题 → 系统 → 经验 → 挑战 → 方向”**

| 模块                             | 内容                                                         | 写作目的                    |
| -------------------------------- | ------------------------------------------------------------ | --------------------------- |
| **标题+摘要**                    | 提出RAGVA系统，基于Transurban真实落地经验，提供开发指南      | 快速传达“经验总结+实践价值” |
| **1. Introduction**              | 指出现有规则型VA的局限 → RAG是趋势 → 但缺乏落地指南 → 本文填补空白 | 引出研究动机和贡献          |
| **2. Background & Related Work** | 回顾规则型VA开发流程、局限性，RAG系统研究现状                | 明确研究空白                |
| **3. RAGVA系统框架**             | 分三步：<br>1. 数据摄入（chunking、embedding、vector store）<br>2. 响应生成（prompt augmentation、LLM、guardrails）<br>3. 评估流程（benchmark、last-mile、real-world） | 提供可复用的系统架构        |
| **4. 焦点小组设置**              | 介绍如何组织9人焦点小组（跨角色、两轮、定性研究）            | 保证经验来源可信            |
| **5. 8大挑战 + 22个RQ**          | 每类挑战都包括：<br>- 问题描述<br>- 现有文献回顾<br>- 未来研究问题（RQ） | 提炼工程痛点，指引研究方向  |
| **6. 实用影响**                  | 如果不解决这些挑战，系统会面临哪些风险                       | 强调问题严重性              |
| **7. 实践建议**                  | chunking策略、embedding/向量库选择、测试用例维护             | 提供落地细节                |
| **8. 威胁到有效性**              | 讨论外部、内部、结构效度限制                                 | 体现研究严谨性              |
| **9. 结论**                      | 总结贡献：框架+挑战+方向                                     | 强调实践价值                |

## 模板句式参考

| 功能     | 模板句式                                                     |
| -------- | ------------------------------------------------------------ |
| 引出痛点 | *Unlike traditional FAQ bots, insurance customers often ask complex, multi-turn questions such as “Does my policy cover physiotherapy after a car accident?”* |
| 描述系统 | *We designed InsureRAG, a retrieval-augmented assistant that ingests 12k insurance documents and answers customer queries in real time.* |
| 提炼挑战 | *We identified eight key challenges, ranging from multimodal claim form processing to adaptive guardrails against hallucinations.* |
| 提出RQ   | *RQ1: How can we automatically detect and redact sensitive personal information in uploaded claim images?* |
| 总结贡献 | *Our experience report provides a reusable framework and an open set of research questions for the insurance RAG community.* |

## 可借鉴的地方

- 论文提出了一个新的概念叫做RAG-VA，把虚拟助手和RAG结合，提出了一个可以应用到生活中的虚拟助手，根据用户输入的问题使用RAG对文档进行检索后返回最相关的文档并且由LLM根据检索内容生成答案后返回。
- 开发一个把RAG应用到实际的智能体

# 论文行文套路的体会

结合前面三篇论文的的总体结构，基本上都是

问题——   中间涉及到数据集或者系统开发的部分 ——实验——结论

```
“问题 → 数据 → 系统 → 实验 → 结论”
“问题 → 系统 → 数据 → 实验 → 结论”
“问题 → 系统 → 经验 → 挑战 → 方向”
```

并且论文的模板句式都差不多

- 引出该研究领域的空白/不足之处/痛点，强调论文的创新点

- 提出论文在该空白领域做出了什么贡献/开发了什么创新性的内容
- 总体概括实验流程，详细描述实验过程，得出实验结论
- 结尾写明局限性/展望/贡献

![image-20250817162241478](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250817162241478-1755418962325-1.png)

![image-20250817162256490](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250817162256490-1755418977779-3.png)

![image-20250817162308644](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250817162308644-1755418990330-5.png)

# 可执行idea路线

## 已经做的

### 检索

之前的检索用的是嵌入—检索，并且尝试了简单检索、混合检索、多查询检索的方式增强检索并引入了两个评估指标。“多查询检索+混合检索+去重”组合效果较好，但是mrr指标偏低

![image-20250818145500085](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250818145500085-1755500101128-1.png)

### 生成

生成部分使用LLM根据检索内容对问题进行回答，并且引入了两个评估指标，分别是ROUGE和BLEU

## 计划做的

### 检索

- 引入重排序的部分，提高mrr
- 参考论文2的LLM智能体+LLM蜂群的思想，在检索部分创建多个智能体
  - 多查询部分：引入5类LLM作为蜂群。5类LLM分别对用户输入的问题进行问题重写，生成重写后的问题
  - 对多查询进行打分：蜂群对重写后的问题进行评估，和用户输入的初始问题进行对比，得出语义最为接近的前三名问题+初始问题进行下一步混合查询
  - 子查询：参考论文2的子查询智能体思想，使用子查询智能体对上一步生成的的四个问题进行拆分，生成多个子问题
  - 混合检索：对子查询生成的多个子问题进行余弦相似度+BM25分数各占一定比例的混合检索
  - 去重：对检索到的文档去重
  - 重排序：再次使用蜂群进行重排序。蜂群独立并发对检索结果进行排序。添加系统，比较检索到的内容，通过**多数投票**或**置信度加权平均**来确定最终的共识结果，得到最后的排序结果


### 生成

- 使用五类LLM作为蜂群，使用不同套提示词根据检索结果生成结果，并且对多个结果进行多数投票，选择票数最高的作为最终结果

## 可行性

现在已经提出了 **Multi-Agent RAG** 或 **Swarm-Enhanced RAG**，类似思路可见于论文 *Self-RAG*（自反思检索）、 *CRAG*（协同检索智能体）

**开源代码**

[AkariAsai/self-rag：这包括 Akari Asai、Zeqiu Wu、Yizhong Wang、Avirup Sil 和 Hannaneh Hajishirzi 的 SELF-RAG：通过自我反思学习检索、生成和批评的原始实现。](https://github.com/AkariAsai/self-rag)

[facebookresearch/CRAG：RAG 的综合基准](https://github.com/facebookresearch/CRAG)

**资料**

[多智能体 RAG 系统 🤖🤝🤖 - Hugging Face 开源 AI 食谱](https://huggingface.co/learn/cookbook/en/multiagent_rag_system)

[The-Swarm-Corporation/AgentRAGProtocol：该协议演示了如何将 RAG 集成到 Agent 中](https://github.com/The-Swarm-Corporation/AgentRAGProtocol)

存在以下缺点：

**静态分工**：智能体角色固定（如始终由固定5个LLM重写问题），**缺乏动态资源分配**

**割裂优化**：检索与生成环节的智能体彼此独立，**未建立跨环节反馈闭环**

**同质化投票**：多数投票机制忽略不同智能体的**领域专长差异**

------

### 创新抓手

#### 🔑 **动态角色分配机制**

- **问题**：图中固定使用“5类LLM”处理所有查询，资源浪费严重

- **您的创新**：

  ```
  # 伪代码：动态智能体调度器
  def agent_scheduler(query_complexity):  
      if query_complexity < threshold_low:    # 简单问题
          return [Agent1]                     # 仅启用基础重写智能体  
      elif query_complexity > threshold_high: # 复杂问题
          return [Agent1, Agent3, Agent5]     # 启用高阶逻辑推理智能体组
      else:                                   # 中等问题
          return [Agent2, Agent4]             # 平衡精度与效率
  ```

  - **理论创新**：提出 **DDSA（Dynamic Difficulty-based Swarm Allocation）模型**

#### 🔑 **跨环节反射机制**

- **问题**：现有方案未利用生成环节的置信度反哺检索

  **反射流程**：

  ```
  生成投票 → 检测低置信度结果 → 触发【检索验证智能体】  
           → 重新检索支持/反对证据 → 修订最终生成
  ```

  ```
  生成投票 → 检测平票 → 触发【辩论智能体】→ 修订最终生成
  ```

  - **技术命名**：**R²RAG（Reflective & Retrieval-Augmented Generation）**

#### 🔑**领域加权投票**

- **问题**：图中“多数投票”未考虑智能体的专业能力差异

- **创新**：

  - **步骤1**：为每个智能体赋予**领域能力向量**

    ```
    Agent1: [医疗:0.9, 法律:0.2]  
    Agent2: [金融:0.95, 科技:0.8]
    ```

  - **步骤2**：计算问题与领域的相关性，动态调整投票权重

    ```
    Final Vote=∑i=1nAgenti(答案)×Sigmoid(Sim(Q,Di))
    ```

# 创新性评估

![image-20250820235523320](./%E7%AC%AC%E5%9B%9B%E5%91%A8-%E6%80%BB%E7%BB%93.assets/image-20250820235523320-1755705324224-1.png)

# 论文框架

## 📌 1. 标题与摘要

说明论文在现有的融入智能体与蜂群的RAG系统上做出的改良，主要包括创建多个类型的智能体如检索验证智能体、辩论智能体，提出了三个创新点，分别是**动态角色分配机制**、跨环节反射机制，领域加权投票。

## 📌 2. 引言

说明RAG现有领域的缺点，对于每个缺点和现有的技术进行讨论，引出创新之处

## 📌 3. 系统设计与流程介绍

提出创新后的RAG流程是如何设计的，各个模块的核心思想是什么

## 📌 4. 实验部分

创建多个智能体的实验流程

验证论文的可行性：

控制变量，设计实验，验证三个创新点单独加入RAG以后系统性能是否提升，提升效果如何

三个创新点一起加进RAG以后提升效果如何

## 📌 5. 实验结论

得出RAG效果改良的效果，并且可以与现有的别的类别的RAG进行对比，或者与同样使用了智能体+蜂群的FISHNET对比

## 📌 6. 不足之处与展望

观察实验设计部分的实验结论，分析实验数据有没有不符合预期的部分，以及可以考虑下一步怎么提升
